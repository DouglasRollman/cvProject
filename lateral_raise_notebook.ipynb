{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d90f7e4a",
   "metadata": {},
   "source": [
    "# Lateral Raise Detection and Counter\n",
    "This notebook uses Mediapipe and OpenCV to detect, validate, and count repetitions of lateral raises. It ensures proper form while visualizing angles and exercise stages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ca6ebd",
   "metadata": {},
   "source": [
    "### References and Setup\n",
    "- Mediapipe Documentation: [Mediapipe Solutions Guide](https://ai.google.dev/edge/mediapipe/solutions/guide)\n",
    "- This notebook relies on the Mediapipe library for pose estimation and OpenCV for video input processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df66716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and import necessary libraries\n",
    "%pip install mediapipe opencv-python\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e07420",
   "metadata": {},
   "source": [
    "### Pose Detection and Analysis\n",
    "- Setup Mediapipe's Pose module to detect body landmarks.\n",
    "- Calculate angles between key landmarks to assess lateral raises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1cb4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate angles between three points\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)  # First point\n",
    "    b = np.array(b)  # Middle point\n",
    "    c = np.array(c)  # End point\n",
    "    \n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    \n",
    "    if angle > 180.0:\n",
    "        angle = 360.0 - angle\n",
    "    \n",
    "    return angle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a8e384",
   "metadata": {},
   "source": [
    "### Exercise Validation and Counting\n",
    "- Validate proper form for lateral raises.\n",
    "- Track repetitions by detecting movement stages (`up` and `down`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829295cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize counters and stage\n",
    "counter = 0\n",
    "stage = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fe46ec",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "- Draw landmarks and pose connections using Mediapipe utilities.\n",
    "- Display angles and movement stages (`up/down`) visually on the video feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575d6543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize angles and stages\n",
    "def visualize(image, left_angle, right_angle, left_elbow, right_elbow, stage):\n",
    "    # Display angles on the video feed\n",
    "    cv2.putText(image, f'Left: {int(left_angle)}', \n",
    "                tuple(np.multiply(left_elbow, [640, 480]).astype(int)), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(image, f'Right: {int(right_angle)}', \n",
    "                tuple(np.multiply(right_elbow, [640, 480]).astype(int)), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    # Display exercise stage\n",
    "    cv2.putText(image, f'Stage: {stage}', (50, 50), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2, cv2.LINE_AA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1a79fa",
   "metadata": {},
   "source": [
    "### Execution Environment\n",
    "- A loop to process real-time video input for dynamic interaction.\n",
    "- Detects poses, calculates angles, validates form, counts repetitions, and visualizes the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1756b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Recolor image to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    \n",
    "    # Make detections\n",
    "    results = pose.process(image)\n",
    "    \n",
    "    # Recolor image back to BGR\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # Extract landmarks\n",
    "    try:\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "        \n",
    "        # Get coordinates for lateral raises (both arms)\n",
    "        left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, \n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "        left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, \n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "        left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, \n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "        \n",
    "        right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, \n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "        right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, \n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "        right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, \n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "        \n",
    "        # Calculate angles\n",
    "        left_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "        right_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "        \n",
    "        # Lateral raise logic\n",
    "        if left_angle > 80 and right_angle > 80:\n",
    "            stage = \"up\"\n",
    "        if left_angle < 30 and right_angle < 30 and stage == \"up\":\n",
    "            stage = \"down\"\n",
    "            counter += 1\n",
    "            print(counter)\n",
    "        \n",
    "        # Visualize output\n",
    "        visualize(image, left_angle, right_angle, left_elbow, right_elbow, stage)\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Render detections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "    \n",
    "    # Display video feed\n",
    "    cv2.imshow('Lateral Raises', image)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
